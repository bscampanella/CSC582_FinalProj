{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd048f99539accd36b27035ab6a120cdcef01e73fa85a1d9090d59c812c30161f25",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from collections import Counter, defaultdict\n",
    "from urllib import request\n",
    "import math\n",
    "\n",
    "charles_dickens = [\"https://www.gutenberg.org/files/98/98-0.txt\", \"https://www.gutenberg.org/files/46/46-0.txt\", \"https://www.gutenberg.org/files/1400/1400-0.txt\", \"https://www.gutenberg.org/files/730/730-0.txt\", \"https://www.gutenberg.org/files/766/766-0.txt\", \"https://www.gutenberg.org/cache/epub/25985/pg25985.txt\", \"https://www.gutenberg.org/files/676/676-0.txt\", \"https://www.gutenberg.org/cache/epub/1023/pg1023.txt\", \"https://www.gutenberg.org/cache/epub/37121/pg37121.txt\", \"https://www.gutenberg.org/files/42232/42232-0.txt\", \"https://www.gutenberg.org/cache/epub/41894/pg41894.txt\", \"https://www.gutenberg.org/cache/epub/1415/pg1415.txt\", \"https://www.gutenberg.org/cache/epub/1394/pg1394.txt\"]\n",
    "\n",
    "marry_shelly = [\"https://www.gutenberg.org/files/84/84-0.txt\", \"https://www.gutenberg.org/files/18247/18247-0.txt\", \"https://www.gutenberg.org/cache/epub/15238/pg15238.txt\", \"https://www.gutenberg.org/cache/epub/6447/pg6447.txt\", \"https://www.gutenberg.org/files/56665/56665-0.txt\", \"https://www.gutenberg.org/files/63337/63337-0.txt\", \"https://www.gutenberg.org/files/63338/63338-0.txt\", \"https://www.gutenberg.org/files/63339/63339-0.txt\", \"https://www.gutenberg.org/files/64555/64555-0.txt\", \"https://www.gutenberg.org/files/64556/64556-0.txt\", \"https://www.gutenberg.org/files/64557/64557-0.txt\", \"https://www.gutenberg.org/cache/epub/4695/pg4695.txt\"]\n",
    "\n",
    "austin_jane = [\"https://www.gutenberg.org/files/1342/1342-0.txt\", \"https://www.gutenberg.org/files/158/158-0.txt\", \"https://www.gutenberg.org/files/161/161-0.txt\", \"https://www.gutenberg.org/cache/epub/105/pg105.txt\", \"https://www.gutenberg.org/files/121/121-0.txt\", \"https://www.gutenberg.org/files/63569/63569-0.txt\", \"https://www.gutenberg.org/files/141/141-0.txt\", \"https://www.gutenberg.org/cache/epub/946/pg946.txt\", \"https://www.gutenberg.org/cache/epub/42078/pg42078.txt\", \"https://www.gutenberg.org/files/1212/1212-0.txt\"]\n",
    "\n",
    "mark_twain = [\"https://www.gutenberg.org/files/142/142-0.txt\", \"https://www.gutenberg.org/files/76/76-0.txt\", \"https://www.gutenberg.org/files/76/76-0.txt\", \"https://www.gutenberg.org/files/3184/3184-0.txt\", \"https://www.gutenberg.org/files/3179/3179-0.txt\", \"https://www.gutenberg.org/cache/epub/19987/pg19987.txt\",\n",
    "\"https://www.gutenberg.org/files/3187/3187-0.txt\", \"https://www.gutenberg.org/files/86/86-0.txt\", \"https://www.gutenberg.org/files/3192/3192-0.txt\", \"https://www.gutenberg.org/files/3180/3180-0.txt\", \"https://www.gutenberg.org/files/3178/3178-0.txt\", \"https://www.gutenberg.org/files/3176/3176-0.txt\"]\n",
    "\n",
    "hg_wells = [\"https://www.gutenberg.org/files/59774/59774-0.txt\", \"https://www.gutenberg.org/files/524/524-0.txt\", \"https://www.gutenberg.org/cache/epub/19229/pg19229.txt\", \"https://www.gutenberg.org/files/59769/59769-0.txt\", \"https://www.gutenberg.org/files/1013/1013-0.txt\", \"https://www.gutenberg.org/files/456/456-0.txt\", \"https://www.gutenberg.org/cache/epub/11502/pg11502.txt\", \"https://www.gutenberg.org/cache/epub/3690/pg3690.txt\", \"https://www.gutenberg.org/files/1046/1046-0.txt\", \"https://www.gutenberg.org/files/3797/3797-0.txt\", \"https://www.gutenberg.org/files/5230/5230-0.txt\", \"https://www.gutenberg.org/cache/epub/159/pg159.txt\", \"https://www.gutenberg.org/cache/epub/39162/pg39162.txt\", \"https://www.gutenberg.org/cache/epub/11640/pg11640.txt\", \"https://www.gutenberg.org/files/1047/1047-0.txt\", \"https://www.gutenberg.org/files/60173/60173-0.txt\"]\n",
    "\n",
    "\n",
    "link_to_authors = [charles_dickens, marry_shelly, austin_jane, mark_twain, hg_wells]\n",
    "\n",
    "\n",
    "def get_files(path):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "gutenberg_directory = './gutenberg'\n",
    "\n",
    "def GetRawText(filename):\n",
    "    f = open(filename, 'r', encoding=\"utf-8\")\n",
    "    raw = f.read()\n",
    "    #remove non book stuff\n",
    "    start_index = raw.find(\"***\")\n",
    "    end_of_line = raw.find(\"\\n\", start_index)\n",
    "    return raw[end_of_line : ]\n",
    "\n",
    "def GetUrlText(url):\n",
    "    response = request.urlopen(url)\n",
    "    raw = response.read().decode('utf8', \"ignore\")\n",
    "    #remove non book stuff\n",
    "    start_index = raw.find(\"***\")\n",
    "    end_of_line = raw.find(\"\\n\", start_index)\n",
    "    return raw[end_of_line : ]\n",
    "\n",
    "def get_works():\n",
    "    authors = get_files(gutenberg_directory)\n",
    "    for i, author in enumerate(authors):\n",
    "        c = Counter([])\n",
    "        filepath = gutenberg_directory + '/' + author\n",
    "        text = GetRawText(filepath)\n",
    "        word_list = []\n",
    "        for word in word_tokenize(text):\n",
    "            word = word.lower()\n",
    "            if word not in stop_words and word.isalpha():\n",
    "                word_list.append(word)\n",
    "        c.update(word_list)\n",
    "        f = open('author_{}.txt'.format(i), 'w', encoding=\"utf-8\")\n",
    "        for word, count in c.most_common():\n",
    "            f.write('{} {}\\n'.format(word, count))\n",
    "        f.close()\n",
    "\n",
    "# get_works()\n",
    "\n",
    "def create_tfidf():\n",
    "    link_count = 0\n",
    "    collect = []\n",
    "    authors = get_files(gutenberg_directory)\n",
    "    for author in link_to_authors:\n",
    "        word_freq = defaultdict(lambda: [])\n",
    "        for i, link in enumerate(author):\n",
    "            link_count += 1\n",
    "            text = GetUrlText(link)\n",
    "            for word in word_tokenize(text):\n",
    "                word = word.lower()\n",
    "                if word.isalpha() and word not in stop_words:\n",
    "                    if word in word_freq:\n",
    "                        freqs = word_freq[word]\n",
    "                        if i not in freqs:\n",
    "                            word_freq[word].append(i)\n",
    "                    else:\n",
    "                        word_freq[word].append(i)    \n",
    "        collect.append(word_freq)\n",
    "    print(link_count)\n",
    "    return\n",
    "    global_dict = defaultdict(lambda: 0)\n",
    "    for c in collect:\n",
    "        for word, doc_list in c.items():\n",
    "            global_dict[word] += len(doc_list)\n",
    "    f = open('tfidf.txt', 'w', encoding=\"utf-8\")\n",
    "    for word, count in global_dict.items():\n",
    "        f.write('{} {}\\n'.format(word, count))\n",
    "    f.close()\n",
    "\n",
    "\n",
    "# create_tfidf()\n",
    "NUM_LINKS = 63\n",
    "def calculate_idf():\n",
    "    idf = []\n",
    "    f = open('tfidf.txt', 'r', encoding=\"utf-8\")\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        word, count = line.split()\n",
    "        count = int(count)\n",
    "        idf.append((word, math.log2(NUM_LINKS / count)+ 1))\n",
    "    f.close()\n",
    "    f = open('tfidf_freq.txt', 'w', encoding=\"utf-8\")\n",
    "    for word, count in idf:\n",
    "        f.write('{} {}\\n'.format(word, count))\n",
    "    f.close()\n",
    "\n",
    "calculate_idf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('He', 'PRP'), ('is', 'VBZ'), ('smart,', 'JJ'), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'), ('punctual', 'JJ')]\n(S\n  (NP He/PRP is/VBZ smart,/JJ)\n  and/CC\n  (NP he/PRP is/VBZ punctual/JJ))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "import re\n",
    "\n",
    "def getSentenceType(statement): \n",
    "    sentenceParts = pos_tag(statement.split()) \n",
    "    return sentenceParts\n",
    "\n",
    "def sentSegs(taggedSent, grammar, loops):\n",
    "    cp = nltk.RegexpParser(grammar, loop=loops)\n",
    "    result = cp.parse(taggedSent)\n",
    "    return result\n",
    "\n",
    "grammar = r\"\"\"\n",
    "        NP:\n",
    "            {<.*>+}\n",
    "            }<IN|CC>+{\n",
    "    \"\"\"\n",
    "\n",
    "sentence = getSentenceType(\"He is smart, and he is punctual\")\n",
    "result = sentSegs(sentence, grammar, loops=1)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}