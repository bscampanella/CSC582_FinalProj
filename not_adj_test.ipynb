{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd01917c364b50b373201183b69312b4f370f1c66530484ad23d950c582ad587b05",
   "display_name": "Python 3.6.12 64-bit ('synqg': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "1917c364b50b373201183b69312b4f370f1c66530484ad23d950c582ad587b05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "red = wn.synsets('red')[0]\n",
    "#print(wn.synsets(\"red\"))\n",
    "# print(red.definition())\n",
    "# print(red.hypernyms())\n",
    "# print(red.hypernyms()[0].hyponyms())\n",
    "print(type(red.hyponyms()[0].lemmas()[0].name()))\n",
    "#print(red.hyponyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Apple apple PROPN NNP nsubj Xxxxx True False\nis be VERB VBZ aux xx True True\nlooking look VERB VBG ROOT xxxx True False\nat at ADP IN prep xx True True\nbuying buy VERB VBG pcomp xxxx True False\nU.K. u.k. PROPN NNP compound X.X. False False\nstartup startup NOUN NN dobj xxxx True False\nfor for ADP IN prep xxx True True\n$ $ SYM $ quantmod $ False False\n1 1 NUM CD compound d False False\nbillion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "of a color at the end of the color spectrum (next to orange); resembling the color of blood or cherries or tomatoes or rubies\n[Synset('red.n.01'), Synset('red.n.02'), Synset('bolshevik.n.01'), Synset('loss.n.06'), Synset('red.s.01'), Synset('crimson.s.02'), Synset('crimson.s.03')]\nSynset('red.s.01')\n[]\n[]\n[]\n[Synset('red.s.01')]\n0\n[]\n"
     ]
    }
   ],
   "source": [
    "hp = wn.synsets(\"red\")[4]\n",
    "print(wn.synsets(\"red\")[4].definition())\n",
    "print(wn.synsets(\"red\"))\n",
    "\n",
    "print(hp)\n",
    "print(hp.hypernyms())\n",
    "print(hp.hyponyms())  # doctest: +ELLIPSIS\n",
    "print(hp.member_holonyms())\n",
    "print(hp.root_hypernyms())\n",
    "print(hp.max_depth())\n",
    "print(hp.lemmas()[0].antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the\nthe the DET\ndog dog NOUN\nis be VERB\ntrue\nhappy happy ADJ\n. . PUNCT\nthe dog is not unhappy it is happy . \n"
     ]
    }
   ],
   "source": [
    "testsent = \"the dog is happy.\"\n",
    "def change_sent(testsent):\n",
    "    fin_text = testsent\n",
    "    negative_replace = \"\"\n",
    "    doc = nlp(testsent)\n",
    "    print(doc[0])\n",
    "    for i, token in enumerate(doc):\n",
    "        print(token.text, token.lemma_, token.pos_)\n",
    "        if token.lemma_ == \"be\":\n",
    "            cur_text = \"\"\n",
    "            \n",
    "            if (len(doc) > i+1) and  (doc[i + 1].pos_ == \"ADJ\") :\n",
    "                print(\"true\")\n",
    "                cur_text = doc[i + 1].text\n",
    "            elif (len(doc) > i+2) and (doc[i + 1].pos_ == \"ADV\" and doc[i + 2].pos_ == \"ADJ\"):\n",
    "                print(\"true2\")\n",
    "                cur_text = doc[i + 2].text\n",
    "            if cur_text != \"\":\n",
    "                cur_synset = None\n",
    "                if len(wn.synsets(cur_text, pos=\"a\")):\n",
    "                    cur_synset = wn.synsets(cur_text, pos='a')[0]\n",
    "                elif len(wn.synsets(cur_text, pos=\"s\")):\n",
    "                    cur_synset = wn.synsets(cur_text, pos='s')[0]\n",
    "                elif len( wn.synsets(cur_text)):\n",
    "                    cur_synset = wn.synsets(cur_text)[0]\n",
    "\n",
    "\n",
    "                if cur_synset:\n",
    "                    if (len(cur_synset.hypernyms()) and len(cur_synset.hypernyms()[0].hyponyms())):\n",
    "                        for hypo in cur_synset.hypernyms()[0].hyponyms():\n",
    "                            if hypo.lemmas()[0].name() != cur_text:\n",
    "                                negative_replace = hypo.lemmas()[0].name()\n",
    "                                print(negative_replace)   \n",
    "                                break\n",
    "                    elif len(cur_synset.lemmas()):\n",
    "                        if len(cur_synset.lemmas()[0].antonyms()):\n",
    "                            negative_replace = cur_synset.lemmas()[0].antonyms()[0].name()\n",
    "                        else:\n",
    "                            for lm in cur_synset.lemmas():\n",
    "                                if lm.name() != cur_text:\n",
    "                                    negative_replace = lm.name()\n",
    "\n",
    "\n",
    "            if negative_replace != \"\":\n",
    "                fin_text = \"\"\n",
    "                for x in range(i + 1):\n",
    "                    fin_text += doc[x].text + \" \"\n",
    "                \n",
    "                #here use the spacy ner to see if a person is in sentence and if so\n",
    "                # them change it to they \n",
    "                fin_text += \"not \" + negative_replace + \" it \" + doc[i].text + \" \"\n",
    "                for x in range(i + 1, len(doc)):\n",
    "                    fin_text += doc[x].text + \" \"\n",
    "    return fin_text\n",
    "\n",
    "print(change_sent(testsent))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "they\nthey -PRON- PRON\nwere be VERB\ntrue2\nvery very ADV\nupset upset ADJ\nabout about ADP\nwhat what NOUN\nhappened happen VERB\nyesterday yesterday NOUN\n. . PUNCT\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'they were not worried it were very upset about what happened yesterday . '"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "change_sent(\"they were very upset about what happened yesterday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}